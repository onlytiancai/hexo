---
title: '202206'
date: 2022-06-02 11:22:45
tags:
---

解读历史波动率，发现交易机会
https://new.qq.com/rain/a/20210830A08VW100

波动率具有聚集性、均值回归、长记忆性和非对称性等特征。

- 聚集性是指波动率具有高低波动率各自聚集的特征，即高波动率之后大概率还是高波动率，低波动率之后大概率还是低波动率，而且高波动率和低波动率聚集的时期会交替出现，呈现出的就是周期性。
- 均值回归是指波动率没有长期上涨或者下跌的趋势，而是围绕均值上下波动。
- 长记忆性指波动率存在较高的自相关特性，现在的波动率在很大程度上取决于其过去的波动率。
- 波动率的非对称性主要体现在隐含波动率上，即标的价格上涨或下跌相同幅度对期权隐含波动率的影响并不相同。

说到企业估值，你怎能不知道现金流折现法？
https://baijiahao.baidu.com/s?id=1722719168861071511

一个公司的内在价值，取决于该公司未来能产生的自由现金流。

自由现金流折现法（Discounted Cash Flow ），简称 DCF。

无杠杆自由现金流/企业自由现金流 
- = EBIT－调整的所得税+折旧摊销—营运资金的增加—资本支出。 
- = 净利润＋利息费用＋所得税－调整的所得税＋折旧摊销—营运资金的增加—资本支出。

---

为了防止 ssh 或 scp 时，提示是否需要确认 hosts，可以提前执行如下语句

    ssh-keyscan abc.com >> ~/.ssh/known_hosts

ssh 或 scp 自动输入密码可以使用 sshpass

    apt-get update
    apt-get  install -y --force-yes sshpass
    sshpass -p "xxxx" scp local remote 


---

Postgree 查看数据库，表，索引大小

查看各个库的大小

    select pg_database.datname, pg_size_pretty (pg_database_size(pg_database.datname)) AS size from pg_database;

查看 public 库下所有表索引大小

    select indexrelname, pg_size_pretty(pg_relation_size(relid)) from pg_stat_user_indexes where schemaname='public' order by pg_relation_size(relid) desc;

查看 public 库下所有表大小

    select relname, pg_size_pretty(pg_relation_size(relid)) from pg_stat_user_tables where schemaname='public' order by pg_relation_size(relid) desc;

查看单个表大小

    select pg_size_pretty(pg_relation_size('表名'));

查询所有表的大小并排序（包含索引）

    SELECT table_schema || '.' || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size('"'
        || table_schema || '"."' || table_name || '"')) AS size
    FROM information_schema.tables
    ORDER BY
    pg_total_relation_size('"' || table_schema || '"."' || table_name || '"') DESC limit 20;


查询表大小按大小排序并分离data与index

    SELECT
    table_name,
    pg_size_pretty(table_size) AS table_size,
    pg_size_pretty(indexes_size) AS indexes_size,
    pg_size_pretty(total_size) AS total_size
    FROM (
    SELECT
    table_name,
    pg_table_size(table_name) AS table_size,
    pg_indexes_size(table_name) AS indexes_size,
    pg_total_relation_size(table_name) AS total_size
    FROM (
    SELECT ('"' || table_schema || '"."' || table_name || '"') AS table_name
    FROM information_schema.tables
    ) AS all_tables
    ORDER BY total_size DESC
    ) AS pretty_sizes;

---

分区，挂磁盘

    # 创建挂载目录
    mkdir /data_ext2/

    # 查看块设备，找到新硬盘
    lsblk
    file -s /dev/nvme2n1
        /dev/nvme2n1: data

    # 分区并查看
    mkfs -t xfs /dev/nvme2n1
    file -s /dev/nvme2n1
        /dev/nvme2n1: SGI XFS filesystem data (blksz 4096, inosz 512, v2 dirs)
    lsblk -f | grep nvme2n1
        nvme2n1     xfs                      de17daa1-9f10-4b60-adc9-2a7ed1557c89

    # 挂载并查看
    mount /dev/nvme2n1 /data_ext2
    df -h /data_ext2

    # 查看设备 id，并设置开机启动挂载
    blkid
    vi /etc/fstab
        UUID=7a0a651a-0000-0000-0000-717708af1dec /data_ext2  xfs  defaults 0 0


---


How to fix "MySQL server has gone away", "Packets out of order" and similar MySQL connection errors
https://www.ryadel.com/en/fix-mysql-server-gone-away-packets-order-similar-mysql-related-errors/

for these errors:
    
    MySQL server has gone away
    Error reading result set's header
    Error executing query
    MySQL server has gone away for query
    2006, MySQL server has gone away
    Packets out of order. Expected X received Y. Packet size=Z

- There's a good chance that the server is dropping an incorrect or too large packet sent by the client. To fix that, check the max_allowed_packet variable value and set it to a very high value
- The issue might be due to the fact that the server timed out and closed the connection. Check the wait_timeout MySQL variable value and ensure it's large enough. 
- Additionally, if you're getting the Packets out of order error in the PHP log, there's an high chance that the issue is due to the fact that there's an incompatibility between the PHP and MySQL versions you're using.

我的一个不常访问的页面使用的如下的代码

    $dbh = new PDO('mysql:host=localhost;dbname=test', $user, $pass, array(
        PDO::ATTR_PERSISTENT => true
    ));

但偶尔报下面的错误，不是经常

    warning: Packets out of order. Expected 1 received 0. Packet size=145

我怀疑是我使用了 MySQL 持久连接，但这个页面不经常使用，造成这个连接长时间保持但没有任何真实请求，然后被 MySQL 单方面杀掉了，但我过了很久之后再刷新页面，PHP 尝试复用这个连接时，被 MySQL 拒绝了。

如果是一个比较活跃的站点，持久连接带来的好处可能比较明显，因为节省了很多连接建立的花时间。但一个请求量比较低的页面没有必要使用持久连接，不知道理解的对不对。

要想真正避免这个问题，我想在执行 SQL 之前要先执行个空的 MySQL ping 命令，验证 MySQL 连接是否有效，如果无效则重新连接，有效则直接使用。这个验证连接的操作可以设置一个缓存时间，比如 1 小时内不需要再次验证，以避免频繁的做无用功。

---

## sql

TODO: MySQL窗口函数OVER()
https://blog.csdn.net/weixin_46544385/article/details/120609601

mysql 快速查看表的数据行数

    set session information_schema_stats_expiry=0;
    show table status like 'mytable'\G


Postgres array_to_string() and array_agg() to decouple your interface
https://pemungkah.com/postgres-array_to_string-and-array_agg-to-decouple-your-interface/

    SELECT Array_to_string(Array_agg(number_of
                                     || ' '
                                     || status), ',  ') summary_status,
           Max(user_id) USER
    FROM   (SELECT Count(*) number_of,
                   status,
                   user_id
            FROM   jobs
            GROUP  BY status,
                      user_id
            ORDER  BY user_id) AS foo
    GROUP  BY user_id;

PostgreSQL:基于数组(外键)列联接2个表
http://ask.sov5.cn/q/rxkaSsHjMA

  SELECT u.id, u.name,array_agg(g.name) group_names FROM users u JOIN groups g ON g.id = ANY (u.group_ids)
  GROUP BY u.id, u.name;

postgree 里的换行

    select 'test line 1'||E'\n'||'test line 2';

postgree 的表 a 有一个数组列 id_arr，格式类似于 `[1,2,3]`，关联到 b 表的 id 列，我想得到 `[a,b,c]`

    SELECT (select string_agg(b.name,',') from b where b.id = ANY(a.ids)) FROM a 


创建临时表，当你断开与数据库的连接后，临时表就会自动被销毁。 临时表只在当前连接中有效。

    CREATE TEMPORARY TABLE 临时表名 AS
    (
        SELECT *  FROM 旧的表名
        LIMIT 0,10000
    );

MySQL 全文索引
https://blog.csdn.net/dreamyuzhou/article/details/120432893

- 全文索引只能用于InnoDB或MyISAM表，并且只能为CHAR、VARCHAR或TEXT列创建。
- MySQL提供了一个内置的全文ngram解析器，支持中文，日文和韩文(CJK)，以及一个可安装的MeCab日文全文解析器插件。 “ngram全文解析器”和“MeCab全文解析器插件”
- FULLTEXT索引定义可以在创建表时在CREATE TABLE语句中给出，也可以稍后使用ALTER TABLE或CREATE index添加。
- 对于大型数据集，将数据加载到一个没有FULLTEXT索引的表中，然后在此之后创建索引，比将数据加载到一个已有FULLTEXT索引的表中要快得多。
- 分区表不支持全文搜索

mysql的全文索引只有一种方法判断相关性，就是词频，索引并不会记录匹配的词在字符串中的位置。并且，全文索引和数据量有较大的关系，全文索引只会全部在内存中时，性能才会很好，因此当全文索引过大，不能全部读入进内存，性能就会比较差。
可以通过一下点，思考下全文索引的问题：

- 修改一段文本中的100个单词时，需要索引100次。
- 全文索引的长度对性能的影响也是巨大的
- 全文索引会产生更多的碎片，需要频繁的优化（optimize table）操作
- 内存和数据容量也是常可观，所以需要规划和参数控制这部分
- 因为mysql复制机制是基于逻辑复制，产生的binlog很大，那就会出现主从延迟等问题。
- 词分割（token_size）也是一个问题，单个汉字也能表达出不同的意思。
- 查询上：如果sql中包含match against，而索引列上又正好有全文索引，那么mysql就一定会使用全文索引，如果此时还有其他索引，mysql也不会去对比那个索引性能更高。

MySQL 创建全文索引

    -- 创建全文索引
    CREATE FULLTEXT INDEX idx ON table_name(`columns`);

    -- 创建表时自动加全文索引，临时表不支持
    CREATE TABLE articles (
      id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
      title VARCHAR(200),
      body TEXT,
      FULLTEXT (title,body)
    ) ENGINE=InnoDB;

    -- 插入测试数据
    INSERT INTO articles (title,body) VALUES
    ('MySQL Tutorial','DBMS stands for DataBase ...'),
    ('How To Use MySQL Well','After you went through a ...'),
    ('Optimizing MySQL','In this tutorial, we show ...'),
    ('1001 MySQL Tricks','1. Never run mysqld as root. 2. ...'),
    ('MySQL vs. YourSQL','In the following database comparison ...'),
    ('MySQL Security','When configured properly, MySQL ...');
    
    -- 简单全文搜索 
    SELECT * FROM articles
    WHERE MATCH (title,body)
    AGAINST ('database' IN NATURAL LANGUAGE MODE);

    +----+-------------------+------------------------------------------+
    | id | title             | body                                     |
    +----+-------------------+------------------------------------------+
    |  1 | MySQL Tutorial    | DBMS stands for DataBase ...             |
    |  5 | MySQL vs. YourSQL | In the following database comparison ... |
    +----+-------------------+------------------------------------------+


    -- 布尔搜索
    SELECT * FROM articles WHERE MATCH (title,body)
    AGAINST ('+MySQL -YourSQL' IN BOOLEAN MODE);

    +----+-----------------------+-------------------------------------+
    | id | title                 | body                                |
    +----+-----------------------+-------------------------------------+
    |  6 | MySQL Security        | When configured properly, MySQL ... |
    |  1 | MySQL Tutorial        | DBMS stands for DataBase ...        |
    |  2 | How To Use MySQL Well | After you went through a ...        |
    |  3 | Optimizing MySQL      | In this tutorial, we show ...       |
    |  4 | 1001 MySQL Tricks     | 1. Never run mysqld as root. 2. ... |
    +----+-----------------------+-------------------------------------+

    -- 查询扩展搜索是对自然语言搜索的修改。
    -- 搜索字符串用于执行自然语言搜索，然后将搜索返回的最相关行的单词添加到搜索字符串中，并再次执行搜索。
    -- 查询返回第二次搜索的行.
    SELECT * FROM articles
    WHERE MATCH (title,body)
        AGAINST ('database' WITH QUERY EXPANSION);

    +----+-----------------------+------------------------------------------+
    | id | title                 | body                                     |
    +----+-----------------------+------------------------------------------+
    |  5 | MySQL vs. YourSQL     | In the following database comparison ... |
    |  1 | MySQL Tutorial        | DBMS stands for DataBase ...             |
    |  3 | Optimizing MySQL      | In this tutorial, we show ...            |
    |  6 | MySQL Security        | When configured properly, MySQL ...      |
    |  2 | How To Use MySQL Well | After you went through a ...             |
    |  4 | 1001 MySQL Tricks     | 1. Never run mysqld as root. 2. ...      |
    +----+-----------------------+------------------------------------------+

---

## laravel

https://zhuanlan.zhihu.com/p/95558910
Laravel 一主多从配置

    'mysql' => [
        'write' => [
            'host' => '192.168.1.180',
        ],
        'read' => [
            ['host' => '192.168.1.182'],
            ['host' => '192.168.1.179'],
        ],
        'driver' => 'mysql',
        'database' => 'database',
        'username' => 'root',
        'password' => '',
        'charset' => 'utf8',
        'collation' => 'utf8_unicode_ci',
        'prefix' => '',
    ]


https://lqwang.net/13.html

- 使用 chunkById 或者 chunk 方法的时候不要添加自定义的排序，chunk和chunkById的区别就是chunk是单纯的通过偏移量来获取数据，chunkById进行了优化，不使用偏移量，使用 id 过滤，性能提升巨大。在数据量大的时候，性能可以差到几十倍的样子。
- 而且使用chunk在更新的时候，也会遇到数据会被跳过的问题。
- 同时 chunkById 在你没有传递 column 参数时，会默认添加 order by id，可能会遇到索引失效的问题。解决办法就是传递 column 参数即可。
- 本人感觉 chunkById 不光是根据 Id 分块，而是可以根据某一字段进行分块，这个字段是可以指定的。


https://laravel.com/docs/master/broadcasting
https://learnku.com/docs/laravel/9.x/broadcasting/12223

For example, imagine your application is able to export a user's data to a CSV file and email it to them. However, creating this CSV file takes several minutes so you choose to create and mail the CSV within a queued job. When the CSV has been created and mailed to the user, we can use event broadcasting to dispatch a App\Events\UserDataExported event that is received by our application's JavaScript. Once the event is received, we can display a message to the user that their CSV has been emailed to them without them ever needing to refresh the page.

- Laravel 通过 WebSocket 连接使它很容易的去「广播」您的服务端 Laravel 事件。
- 广播 Laravel 事件允许您在服务器端 Laravel 应用程序和客户端 JavaScript 应用程序之间共享相同的事件名称和数据。
- 广播背后的核心概念很简单：客户端连接到前端的命名频道，而您的 Laravel 应用程序将事件广播到后端的这些频道。
- laravel-websockets 和 soketi 包为 Laravel 提供了与 Pusher 兼容的 WebSocket 服务器。 这些包允许您在没有商业 WebSocket 提供程序的情况下利用 Laravel 广播的全部功能。


---

## 算法

经典面试题：如何快速求解根号2？
https://mp.weixin.qq.com/s/ONv1k27PflPZstlv99Vfzw

如何最简单、通俗地理解LSTM？
https://www.zhihu.com/question/445411028/answer/2323876011

- LSTM 是一种 RNN 模型
- LSTM 是对简单循环神经网络的改进
- LSTM 可以避免梯度消失的问题，可以有更长的记忆

大白话理解LSTM神经网络（附实例讲解）
https://blog.csdn.net/Iceberggg/article/details/124114192


长短期记忆神经网络（LSTM）是一种特殊的循环神经网络(RNN)。原始的RNN在训练中，随着训练时间的加长以及网络层数的增多，容易出现梯度爆炸或梯度消失的问题，导致无法处理较长序列数据，从而无法获取长距离数据的信息。为解决该问题，提出了它的改进方案，即LSTM神经网络。

设计思路
- RNN 神经网络：记住所有信息，无论是有用的还是无用的。
- LSTM 神经网络:选择一个记忆细胞，对信息有选择性地记忆。

前向传播
- t 为时刻
- C_{t} 为记忆细胞
- h_{t} 为状态
- x_{t} 为输入
- f_{t} 为遗忘门
- i_{t} 为更新门
- o_{t} 为输出门

举例

- 假设现在是期末考试周且你的脑容量有限，昨天你考完了高等数学，后天将考线性代数，你的线性代数老师也为你贴心地划好了考试重点。
- RNN会记住所有的信息，无论是有用信息还是无用信息，即你复习了整本线性代数的书本，并将其内容与上一门高等数学的内容全部记忆了下来
- 对于LSTM来说，你将遗忘大部分高等数学的内容，而只保留基础数学运算等通用内容，并且只复习记忆线性代数书本中老师划出的重点。
- `C_{t} X f_{t}` 的会生成一系列 0-1 之间的数，如[0，1，0.7，0，0.3，1]，对其赋权重后，进行选择性遗忘。
    - 遗忘大部分高等数学的知识，记忆能够用到线代考试中的基础数学运算等知识。
- `i_{t}` 更新门
    - 老师所划出的重点并不会全部出现在试卷上，你可以在复习的过程中根据自己的理解，判断哪些内容可能考，哪些内容肯定不考，由此再进行筛选过滤。
- 在 LSTM 的每个时间步里，都有一个记忆 cell，给予 LSTM 选择记忆的功能。

请问rnn(lstm)和hmm在处理序列问题上的区别和优缺点在于？
https://www.zhihu.com/question/55007302/answer/1744376871

- 在特定问题下，参数设置正确，相关论文已经证明HMM与LSTM能达到类似的效果。
- 但是越先进的模型，调参成本越低。
- 在时间序列预测问题上，可能 LSTM 不需要做特别多的参数调整就优于 HMM
- 自然语言处理上，BERT 不需要做特别多的参数调整就优于 LSTM

深度学习做股票预测靠谱吗？
https://www.zhihu.com/question/54542998/answer/2361320437

- 我有无数的本科生从youtube上抄了一堆直接应用LSTM在股票价格上的预测，说r^2高达99%，然后我让他们用daily return做一遍，立刻不说话了。
- 究其原因，是股票价格的时间序列非常persistent，而在take first-order difference之后，return的信噪比又过低，所以LSTM肯定没办法。
- LSTM在经济学里适合做什么呢？适合做宏观数据，一群月度季度宏观数据放在一起train，得到的结果是非常棒的。为什么呢？因为宏观本来就有lead-lag indicators，你LSTM做的是定量上的贡献。
- 在去掉seasonality之后如果还有很多信息，那么LSTM才会好（例如宏观数据）。
- lstm 绝对是靠谱的。我就知道国内某头部量化2017 年到2019年用lstm做出了很好的收益。但具体做法绝对不是一般人想的那么简单。任务的目标、使用的数据、处理的特征，都不是一般人能想到的
- 任务的目标是个很重要的问题，很多人都没考虑清楚任务的目标就上LSTM
- 如果预测价格而不是return，线性模型都能给搞出高R^2来，把价格作为预测目标说明完全没有上道在胡做一气。不要预测价格，要预测收益率。
- 在不讨论因子有效性的前提下讨论模型work不work没有意义。没有因子，别玩模型。
- 混沌理论，尤其李天岩教授的研究，对股市预测有一定的帮助。所以金融领域，混沌理论应该是正确的突破方向。
- 幻方之前的报告明确表示，小资金量只用盘口数据+LSTM是可以赚钱的，但是他们也说特征工程有trick（估计有什么自己的因子） 
- 宏观惯性大，微观在搞布朗运动
- 不是LSTM不行，而是关键方法设计和改进需要适合数据特性，做好预处理，做好需要处理的各种多模态数据的准备…毕竟直接套用LSTM，那是肯定不行…LSTM背后应该是一类方法，而不只是调用出来的tf里的一个确定的方法
- 特征挖得好加点非线性就能work，和lstm关系也不大
- 单变量序列，前后变化幅度上下0.1，不平稳，硬套lstm[飙泪笑] 老师！我有个时间复杂度O(1)的好主意，和你lstm一个水平：x(t) = x(t-1)[飙泪笑] 换daily return了？老师这题我也会！x(t) = mean(x[t-n: t-1])
- feature不行吧，对着一堆噪声再好的模型也学不到语义，而且直接上lstm也太…
- 时序的默认假设就是有很强的关联性。单股数据内在关联实际上很弱，也就是所谓的信噪比非常低。这种情况下，越强的神经网络越容易出问题。因为噪声模式占主导，不经过特定的特征选择和滤噪，基本上只有过拟合噪声一条命。
- 对价格建模确实精确的一无是处
- 其实最大问题是时序非稳态，随着时间的变化时序的模式变了，机器学习还是按照过去训练集给出的模式来预测，结果肯定拉跨。说到底非稳态时序预测就是搞不定，arima不行，啥神经网络也不是万能药。
- lstm 在高频预测方面还是有一定收益的
- 如果是youtube上面涉及到的first difference的方法我见过大部分是只使用股票价格去套lstm。这个问题出在数据上而不是lstm这个模型本身有没有效。
- 如果训练数据本身对结果就没有说明度模型选什么model已经不重要了……现在业内普遍的做法是训练数据用的因子是截面的基本面+量价因子（类MSCI Barra 或者Fama的做法），target用收益率或者对数收益率。
- 如果做非线性模型除了单lstm还有CNN+LSTM或者几种stacking的做法，做RF的也有，反正这个见仁见智吧跟设备还有交易速度也有关。
另外宏观跟微观世界也差很多……有时候tick级动量因子就很有效反而日间的时候无效，有时候正好相反。
- 另外不同市场区别也很大，之前有段时间开盘那段趋势性很强，然后就有人做那种开盘型的momentum策略，结果最近日内波动上来了被爆锤。
- 归根结底，海量有效的因子库还是基础，模型是5%-6%的问题（这个我随便臆测的数哈不一定对，重点还是放在因子上）。
- 所以现在头部量化都是疯狂卷设备，招一堆因子民工进去挖因子，毕竟越同质化的因子注定策略收益越会被其他使用相同因子的同类策略压缩掉，总之是越来越卷
- 为什么说return信噪比低呢？这不应该比close 高？对数化遮盖了很多低频信息
- 预测return和你说的那些任务，难度和收益的差别堪比打游戏和打赢一场战争。。并且也不应该指望很高的r2，0.01就有用处了。0.1就逆天了
- 如果把预测股票视为一个分类问题，0跌 1涨呢？
    - 方向准确率也比较难有比随机猜的50%更好的效果，而且拿方向准确率交易本身也不靠谱，就算能到75%，也有可能3天赚的钱1天直接双倍亏回来。
    - 如果真的有75%，我完全可以分散成20个仓位，取预测上涨百分比最高的前20，上涨的概率越大仓位分配重，不多贪，每天能吃1个点一年都是10倍，三年一千倍
    - 比特币分钟线搞过52%准确率的，期望收益率十万分之五每分钟
- 做差分或者对return rate做预测或者是对01涨跌分类预测会不会work（比last day baseline好）
    - 预测收益率or Diff是最最最基本的…work与否取决于因子质量，模型没有门槛，但因子库有。
- 模型不是越高深效果越好，而是有各自适用的范围。比如，如果linear regression都过拟合，那用ML和DL就没什么意义了。
- 我个人的经验，日度的数据，用ML预测无卵用，加上盘口的高频数据ML倒是有可做的空间，但是还是无法满足DL对数据的质量要求。
- 当然，如果是对策略进行优化，而不是纯以预测股价为目的，ML应该会有更多的应用空间。但总而言之DL现在做量化的应该是几乎不用的。
- 一圈实验下来，确实觉得对策略优化是大概率的没走“邪路”。尤其是只用日频数据的alpha类策略，用ML来预测市场就像水中捞月。
- 不论回归，分类，不管统计学习，机器学习，深度学习，都是跑的概率。可以说是对你“见过的数据”做了一次拟合实验，想找到里面的规律――概率。
- 下围棋是归纳还是博弈？
    - 下围棋是两人之间的博弈没错，但是深度学习alphago在这里面的作用起的是归纳历史棋局的作用。围棋虽然复杂，但是规则是有限的，也是明确的，所以在大量数据和高性能计算上，深度学习通过归纳下围棋的方法能打赢人类。但是市场跟围棋不一样，市场由于有很多人参与，规则是无限的，也是不明确的，很难用一个统一的模型去寻找规律。当然有可能存在短时间某种规律一直有效的情况，所以说有些因子在某些特定环境有效。
- 如果说机构还能构建模型，对散户来说应该是通过归纳找出某周期内胜率大于50%的操作方式，合理设置盈亏比，严格执行之。并时时统计这个周期内胜率变化，一旦变化，相应策略也要调整。市场是混沌的，预测冇意义，一切都是概率变化而已
- 股市预测的问题本质上是一个online learning 的问题，因为股票市场上的规律是不断地在变的。这也是为什么传统机器学习方法和深度学习方法在金融市场上容易被当成笑话的原因。也因此，reinforcement learning 是显然不适合金融市场的，reinforcenment learning的反馈太慢了，所以需要大量的数据才能学到数据背后的规律。显然，在online learning场景下我们没有办法提供大量的数据。
- 我觉得深度学习还是可以用来做投资的，而非交易。
    - 我觉得可以。最起码可以做交易员的辅助交易。因为有些隐规则是人自身没有发现的，但是机器可能会发现，一个好的高频预测模型是可以做出来的，因为短期内环境不会有大的变化，就可以预测。如果深度学习能够学习其中的隐规则，并且使用模型输出人能够理解的信息形式，就是一个很好的预测模型
- 市场追求的不是博弈，而是共识。 同样2020年3月为例，绝对的利空，造成统一的救市共识，然后才挽救了股市。放在1927年、2000年，市场在救与不救之间徘徊不定无法达成共识，造成了灾难性后果。
- 深度学习肯定是可以用在股票市场的，比如针对某只股票的新闻情感分析等。但是不能用来预测市场走向！！！

人工智能基础课，最优化

求解无约束优化问题最常用的方法是梯度下降法（gradient descent）。直观地说，梯度下降法就是沿着目标函数值下降最快的方向寻找最小值，就像爬山时要沿着坡度最陡的路径寻找山顶一样。在数学上，梯度的方向是目标函数导数（derivative）的反方向。

当函数的输入为向量时，目标函数的图象就变成了高维空间上的曲面，这时的梯度就是垂直于曲面等高线并指向高度增加方向的向量，也就携带了高维空间中关于方向的信息。而要让目标函数以最快的速度下降，就需要让自变量在负梯度的方向上移动。这个结论翻译成数学语言就是“多元函数沿其负梯度方向下降最快”，这也是梯度下降法的理论依据。

遗憾的是，梯度下降法无法获知关于导数的变化信息，也就不知道应该探索导数长期为负的方向。由于不具备观察目标函数的全局视角，在使用中梯度下降法就会走出一些弯路，导致收敛速度变慢。而二阶导数所包含的全局信息能够为梯度下降的方向提供指导，进而获得更优的收敛性。

如果将二阶导数引入优化过程，得到的典型方法就是牛顿法（Newton's method）。在牛顿法中，目标函数首先被泰勒展开，写成二阶近似的形式（相比之下，梯度下降法只保留了目标函数的一阶近似）。此时再对二阶近似后的目标函数求导，并令其导数等于 0，得到的向量表示的就是下降最快的方向。相比于梯度下降法，牛顿法的收敛速度更快。


群蚁算法、遗传算法、模拟退火算法，禁忌搜索算法等通俗详解
https://blog.51cto.com/u_13682052/2981273

单只蚂蚁的行为及其简单，行为数量在10种以内，但成千上万只蚂蚁组成的蚁群却能拥有巨大的智慧，这离不开它们信息传递的方式——信息素。蚂蚁在行走过程中会释放一种称为“信息素”的物质，用来标识自己的行走路径。在寻找食物的过程中，根据信息素的浓度选择行走的方向，并最终到达食物所在的地方。信息素会随着时间的推移而逐渐挥发。在一开始的时候，由于地面上没有信息素，因此蚂蚁们的行走路径是随机的。蚂蚁们在行走的过程中会不断释放信息素，标识自己的行走路径。随着时间的推移，有若干只蚂蚁找到了食物，此时便存在若干条从洞穴到食物的路径。由于蚂蚁的行为轨迹是随机分布的，因此在单位时间内，短路径上的蚂蚁数量比长路径上的蚂蚁数量要多，从而蚂蚁留下的信息素浓度也就越高。这为后面的蚂蚁们提供了强有力的方向指引，越来越多的蚂蚁聚集到最短的路径上去。


继续考虑寻找f(x)最大值的问题，爬山算法搜索到A点时就会停止搜索，原因是A点左右的值均小于A点的值。模拟退火算法采用的解决办法是以一定的概率选择A两边的点，尽管A两边的点并不是局部最优解，这样就有一定的概率搜索到D点，从而搜索到B点，最终获得了全局最优解。上文中的一定概率来自于固体退火原理：当固体温度较高时，物质内能较大，固体内部分子运动剧烈；当温度逐渐降低时，物体内能也随之降低，分子运动趋于平稳；当固体温度降到常温时，固体内部分子运动最终平稳。根据Metropolis准则，粒子在温度T时趋于平衡的概率为e^(-ΔE/(kT))，其中E为温度T时的内能，ΔE为其改变量，k为Boltzmann常数。


TODO: numpy实现朴素贝叶斯模型（高斯分布）
https://www.jianshu.com/p/efa980944235

    import numpy as np


    class GaussianNB():

        def fit(self, X, y):
            """模型拟合"""
            self.y_prior = [round(sum(y == i) / len(y), 6) for i in sorted(set(y))]
            self.features_param = []

            for i in sorted(set(y)):
                pos = np.where(y == i)
                features_data = X[pos]
                features_mean = np.mean(features_data, axis=0)
                features_std = np.std(features_data, axis=0)

                param = [(round(avg, 6), round(std, 6)) for avg, std in zip(features_mean, features_std)]
                self.features_param.append(param)

        def predict(self, x):
            """模型预测"""
            result = []
            for i in range(x.shape[0]):
                bayes_prob = []

                for j in range(len(self.y_prior)):
                    x_param = self.features_param[j]
                    y_param = self.y_prior[j]
                    xi_conditional_prob = 1

                    for k in range(len(x_param)):
                        xi_conditional_prob *= self.gauss_pro(x[i][k], x_param[k][0], x_param[k][1])
                    bayes_prob.append(round(y_param * xi_conditional_prob, 6))
                result.append(np.where(bayes_prob == np.max(bayes_prob))[0][0])

            return np.array(result)

        def gauss_pro(self, v, miu, sigma):
            """高斯分布概率密度计算"""
            part1 = 1 / (sigma * np.sqrt(2 * np.pi))
            part2 = np.exp(-1 * (v - miu) ** 2 / (2 * sigma ** 2))
            return round(part1 * part2, 6)


    if __name__ == '__main__':
        from sklearn import datasets

        iris = datasets.load_iris()
        X = iris.data
        y = iris.target

        gnb = GaussianNB()
        gnb.fit(X, y)

        res = gnb.predict(X)
        print(res)

## Neo4j

neo4j使用文档
https://www.cnblogs.com/naimao/p/13497046.html

- 它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎，
- 它将结构化数据存储在网络(从数学角度叫做图)上而不是表中。
- 图形数据库数据模型的主要构建块是：节点、关系、属性
- neo4j主要存储节点和关系，其中关系必须为有向关系，描述节点和关系的数据以属性的形式存储，节点和关系上都能放键值对的属性。不同类型的节点和关系通过标签Label来区别，不同标签的节点代表不同类型节点，不同标签关系代表不同类型关系

创建一个标签为Person的节点，其有属性 name 和age：

    create (:Person{name:'小红',age:21});

查询一个节点：

    match (m:Person{name:'小红',age:21}) return n;

删除一个节点：

    match (m:Person{name:'小红',age:21}) delete n;



创建关系：

    create (a:Person{name:"a"}),(b:Person{name:"b"}) with a,b create (a)-[r:Friend]->(b);

查询关系：

    match (a:Person{name:"a"})-[r:Friend]->(b:Person{name:"b"}) return r;

删除关系：

    match p=(a:Person{name:"a"})-[r:Friend]->(b:Person{name:"b"}) delete p;

---

## linux

Linux--网络通信命令(给其它用户发送广播消息)
https://blog.csdn.net/qq_42119367/article/details/123427804

    wall Happy New Year

http://ipcmen.com/nano

nano 是一个字符终端的文本编辑器，有点像 DOS 下的 editor 程序。它比 vi/vim 要简单得多，比较适合Linux初学者使用。

- 移动光标：使用用方向键移动。
- 复制一整行：Alt+6
- 剪贴一整行：Ctrl+K
- 粘贴：Ctrl+U
- 如果需要复制／剪贴多行或者一行中的一部分
    - 先将光标移动到需要复制／剪贴的文本的开头
    - 按 Ctrl+6（或者 Alt+A ）做标记
    - 然后移动光标到 待复制／剪贴的文本末尾。这时选定的文本会反白
    - 用 Alt+6 来复制，Ctrl+K 来剪贴。
    - 若在选择文本过程中要取消，只需要再按一次 Ctrl+6。
- 退出: Ctrl+X: 如
    - 果你修改了文件，下面会询问你是否需要保存修改。
    - 输入Y确认保存，输入N不保存，
    - 按 Ctrl+C 取消返回。
    - 如果输入了Y，下一步会让你输入想要保存的文件名。
        - 如果不需要修改文件名直接回车就行；
        - 若想要保存成别的名字（也就是另存为）则输入新名称然后确定。
        - 这个时候也可用 Ctrl+C 来取消返回。
- 撤销：Alt+U
- 重做: Alt+E

Linux visudo配置详解
http://t.zoukankan.com/wutao1935-p-10045809.html

sudo的工作过程如下：

- 当用户执行 sudo 时，系统会主动寻找 /etc/sudoers 文件，判断该用户是否有执行 sudo 的权限
- 确认用户具有可执行 sudo 的权限后，让用户输入用户自己的密码确认
- 若密码输入成功，则开始执行 sudo 后续的命令
- root 执行 sudo 时不需要输入密码 (sudoers 文件中有配置 root ALL=(ALL) ALL这样一条规则)
- 若欲切换的身份与执行者的身份相同，也不需要输入密码

visudo 使用 vi 打开 /etc/sudoers文件，但是在保存退出时，visudo 会检查内部语法，避免用户输入错误信息

    # 允许 user1 用户执行任意路径下的任意命令
    user1 ALL=(ALL) ALL
    # 允许 user1 用户不输入该用户的密码的情况下使用所有命令
    user1 ALL=(ALL) NOPASSWD: ALL
    # 允许 user1 用户执行特定命令
    user1 ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom

---

## 量化

从零入门量化交易系列(十二)Black-Litterman模型及python实现
https://zhuanlan.zhihu.com/p/363540266

这里还要再说一个重要的假设就是共轭分布，千万别被共轭（conjugate）这个词吓到，它几乎是整个Black-Litterman模型在形式上的核心。原因在于一个正态分布乘以另一个正态分布结果还依然是正态分布。这就是为什么模型不仅要假设\mu服从正态分布，连投资者的观点也要假设为正态分布的原因。这两个正态分布都在分子上，相乘后结果仍为正态分布，而分母上的积分为常数，并不影响新的正态分布的均值和方差。也就是说先验和后验同属于正态分布，两者共轭，因此后验分布的均值方差都可以根据公式快速得到。这也就方便我们得到后验分布的均值，也就是我们想要的期望收益率。

【量化模型】Black-Litterman模型介绍
https://zhuanlan.zhihu.com/p/25041459



Markowitz的MPT模型：给定风险水平下的预期收益最大化，也可以是其对偶命题，给定预期收益 水平下的风险最小化。

- 缺点：
    - 假设不成立：MPT理论假设为投资者一致且理性（即投资者对预期收益、标准差和风险资产相关性具有一致预测；投资者行为遵循最优化原则，即投资者理性）。现实中显然不成立。
    - 无仓位限制：在无卖空限制条件下，MPT模型经常导致在一些资产上有很大的空头头寸，而实际上大量投资者具有卖空约束。中国市场对卖空进行限制，模型经常导致在某些资产上权重为零，而在另一些资产上权重过大，即出现资产配置过于集中的现象。
    - 参数敏感：对输入参数如预期收益率作小幅度变化，可能导致模型结果发生剧烈变化。
- 改进：
    - 高盛的Fisher Black和Robert Litterman在研究中发现，对组合中德国债券预期报酬率做0.1%小幅修正后，竟然该类资产的投资比例由原来的10.0%提高至55.0%。
    - 做法：加入投资者自己的观点，而且有一定的置信水平。二人提出了BL模型：使用Bayes定理（条件概率），构建收益时通过一定方式对市场隐含收益率与主观预期收益的加权平均。



Black-Litterman模型是基于MPT基础上的资产配置理论。BL模型在隐含市场收益率和分析师主观预测信息的基础上，成功解决了MPT模型中假设条件不成立，参数敏感等问题。

- BL优化后确实战胜市场均衡配置；
- BL模型同样也存在模型上的缺陷，需要继续改进。历史数据计算出来的协方差矩阵在长期内可能不能良好刻画出短期关系，需要动态调整；分析师主观预期（看法）信心水平的设定具有很大的主观 随意性，在方法上还存在众多分歧；
- BL模型比较符合目前国内基金投资真实市场环境，如关注分析师主观预期，存在投资仓位上下限规定等；
- BL模型适用于行业资产配置，而一般不配置具体的投资，倾向区分大类资产；但有的地方也说可以用在个股组合中；
- 达里奥桥水基金的全球配置更关注风险因子，而非大类。股票中的能源股和部分大宗商品息息相关，从而分配到相同的一类中。是不同于MPT和BL的资产配置理论

大奖章基金
https://baijiahao.baidu.com/s?id=1664399262080636944&wfr=spider&for=pc

- 该基金的收费比较高，管理费为 5%，业绩分成比例为 36%。
- 奖章基金的管理规模在 100 亿美金左右，折合人民币约 700 亿。
- 二十年年化收益率近 70%

【矩阵分析】Condition Number
https://zhuanlan.zhihu.com/p/81053589

- 我们在衡量某个函数敏感度与稳定性时，常使用的一种方法是求导。即观察导数[公式] 的大小。
- 然而对于一个矩阵而言，所谓的导数似乎就不是那么显著，在此我们就介绍一个常用的指标矩阵敏感度指标：Condition Number。

TODO: 因子分析的数学基础
https://zhuanlan.zhihu.com/p/348566335

- 1.1 方差
- 1.2 标准差
- 1.3 均方误差
- 1.4 python实现
- 1.5 协方差
- 1.6 相关系数
- 1.7 特征值和特征向量
- 1.8 使用Python求解特征值和特征向量
- 1.9逆矩阵和转置矩阵
- 1.10 矩阵的迹和行列式

多元函数泰勒级数展开_用Python学微积分(4)---泰勒级数
https://blog.csdn.net/weixin_39906358/article/details/111639431

---

WaveFunctionCollapse
https://github.com/mxgmn/WaveFunctionCollapse

动态生成迷宫

---

## shell

查看 json 压缩文件里倒数第 2 行的 id， 因为有可能是个末尾损坏的压缩包，所以跳过倒数第一条数据

    zcat ./out_000000168373001.gz 2>/dev/null | tail -n2 | head -n1| jq -r '.id'

---

https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html

Think before disabling the _source field
Users often disable the _source field without thinking about the consequences, and then live to regret it. If the _source field isn’t available then a number of features are not supported:

- The update, update_by_query, and reindex APIs.
- On the fly highlighting.
- The ability to reindex from one Elasticsearch index to another, either to change mappings or analysis, or to upgrade an index to a new major version.
- The ability to debug queries or aggregations by viewing the original document used at index time.
- Potentially in the future, the ability to repair index corruption automatically.


https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-id-field.html

- Each document has an _id that uniquely identifies it, which is indexed so that documents can be looked up either with the GET API or the ids query. 
- The _id can either be assigned at indexing time, or a unique _id can be generated by Elasticsearch. 
- This field is not configurable in the mappings.

---

https://www.517712.com/gupiao/94304.html

美元加息对黄金影响的三种情况：

1、美元加息利好黄金：美元加息，但货币并未成功回流流回银行系统，而企业贷款利率上涨，贷款困难，就会出现流动性危机，美元会被看空，对黄金就是利好。
2、美元加息利空黄金：美元加息，存款利率上涨，货币顺利回流银行系统，美元升值，对黄金就是利空。
3、美国加息，美元升值，但同时出现地区性动荡、石油危机等情况影响正常经济发展，对黄金有利好作用，就是美元和黄金同时上涨。


国际现货黄金是以美元来定价的，因此美元和黄金价格呈现一定的负相关关系，换句话说当美元上涨时，黄金价格大概率是下跌，而当美元下跌时，黄金价格大概率是上涨。

---

NGINX Proxy to wordpress website
https://stackoverflow.com/questions/38205743/nginx-proxy-to-wordpress-website

    location ^~ /blog/ {
      proxy_pass http://127.0.0.1:8080/;
      proxy_set_header Host $http_host;
      proxy_set_header X-Forwarded-Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;
    }

    /** set the site URL */
    define('WP_HOME','http://www.example.com/blog');
    define('WP_SITEURL','http://www.example.com/blog');

    /** Fix to get the dashboard working with the reverse proxy.*/
    $_SERVER['REQUEST_URI'] = str_replace("/wp-admin/", "/blog/wp-admin/",  $_SERVER['REQUEST_URI']);


Gutenberg breaks completely if site URL is not the same as wordpress URL
https://github.com/WordPress/gutenberg/issues/1761    


---


反射放大攻击
https://baijiahao.baidu.com/s?id=1730701810134759899

所谓的反射放大攻击是非常常见的DDoS攻击手法，其基本原理非常简单：攻击者通过控制僵尸网络伪造靶机IP向特定的公网服务器发送请求，公网服务器收到请求后会向靶机发送更大的应答报文，从而实现攻击流量放大。

这里的公网服务器是指对外开放某些可被利用作反射放大的协议端口的服务器，比较常见的协议有DNS、NTP、SNMP、Memcached等，这些协议一般基于UDP，并且协议本身存在缺陷，没有校验来源IP的真实性，且存在应答报文远大于请求报文等特点。这种反射放大手法简单、有效，一直深受黑客喜爱，所以很长一段时间内UDP反射就是反射放大攻击的别称。

早在2018年就出现利用公网服务器开放的TCP端口进行反射攻击的手法，相比UDP反射放大攻击，此类利用TCP协议栈的反射攻击实际并无太明显的流量放大效果，因为请求的来源IP是伪造的，无法与TCP服务器完成TCP三次握手建立连接，所以无法得到应用层的应答报文。但是这种攻击利用了TCP的协议栈特性，使靶机看到攻击流量具备协议栈行为，而且成份复杂(synack、ack、rst等混合流量)，导致反向挑战、协议栈行为校验等传统的TCP防护算法无法防护，大大增加了防护难度，所以这种TCP反射诞生后很快成为DDoS攻击的主流攻击手法。

放大系数可以理解为流量的放大倍数，计算方法非常简单，就是response总长度/query总长度。传统的UDP反射攻击的放大系数与具体的协议实现相关，所以放大系数是一个相对固定的值：除了Memcached反射攻击以外，其他UDP反射放大系数不超过600，而且以200以内为主。

---

## nginx

A Guide to Caching with NGINX and NGINX Plus
https://www.nginx.com/blog/nginx-caching-guide/

## docker

docker数据卷与数据卷容器以及备份与恢复
https://blog.csdn.net/m0_60360828/article/details/122641289

创建容器

    docker run -it -v /opt --name test_1 centos:7 /bin/bash

        echo "123321" > /opt/1.txt

备份

    docker run -it --volumes-from test_1 -v /mnt:/mnt centos:7 tar cvf /mnt/opt.tar /opt

- `--volumes-from test_1` ：指定数据卷容器所在
- `-v /mnt:/mnt`：共享该容器中mnt目录到主机的mnt
- `tar cvf /mnt/opt.tar /opt`：这个较为绕，mnt是该容器跟主机之间共享的一个目录。所以将备份后的数据放到这个文件中，好备份之后直接导到主机。
- 后面跟随的备份目标路径，则是该容器与数据卷容器之间的共享目录，因为要对数据卷容器进行备份，所以则是需要备份该目录

查看备份

    ls /mnt/
    tar xvf opt.tar
    cat ./opt/1.txt

恢复

    #创建数据卷容器，并且共享opt目录
    docker run -it -v /opt --name test_2 nginx:1.12 /bin/bash

    #创建一个容器，作用是从主机中获取文件，并且将该文件传输给数据卷容器
    docker run -itd --volumes-from test_2 -v /mnt:/mnt nginx:1.12 tar xvf /mnt/opt.tar -C /opt/

    cd opt/ && ls
    cat ./opt/1.txt

## elasticsearch 

Field data typesedit
https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html

Each field has a field data type, or field type. This type indicates the kind of data the field contains, such as strings or boolean values, and its intended use. For example, you can index strings to both text and keyword fields. However, text field values are analyzed for full-text search while keyword strings are left as-is for filtering and sorting.

## pandas

设置时间索引

    data['time_key'] = pd.to_datetime(data['time_key'])
    data.set_index('time_key', inplace=True)

设置图表默认大小

    from matplotlib import pyplot as plt 
    plt.rcParams['figure.figsize'] = (16, 8)

两个指标各用一个坐标轴

    data[['close','volume']].plot(secondary_y=['volume'])

两个指标各用一个子图

    fre[['fre','cumsum']].plot(subplots=True)

分成 10 段，显示每个段的数量

    data['real_vol_22'].hist(bins=10)

pandas数据可视化原来也这么厉害
https://baijiahao.baidu.com/s?id=1684407979428084767&wfr=spider&for=pc

pandas 区间间隔 pd.Interval
https://www.gairuo.com/p/pandas-interval

---


## 理财

无风险数字货币套利之三角套利
https://zhuanlan.zhihu.com/p/394421805

三角套利，是指交易者利用三种不同的数字货币的价格不匹配的过程。 通过买卖这些特定货币，交易者获得了无风险的利润。 这种失配通常只会持续几秒钟，因为有大量的交易员正在积极寻找这样的机会，因此三角套利主要是通过程序化的量化交易来完成的。

以btc、eth和usdt三种数字货币来说，而交易所存在eth/btc、eth/eos、btc/eos三个交易对，同时三个交易对之间存在价差，那么首先可以使用价值400元的eth购买对应份额的eos，而后在使用这些的eos兑换成btc，最后可以将兑换btc兑换成eth，那么最终结果就是你净赚10元，同时又由于这些交易都是瞬时完成的，也就可以近似认为是无风险套利了，其中唯一的风险就是别人比你的交易速度更快。

三角套利是利用交叉汇率定价错误进行的套利。套利使得实际交叉汇率与理论交叉汇率保持一致。在国际市场上，几乎所有的货币兑美元都有一个兑换率。两个非美国国家之间的理论汇率可以从它们与美元之间的汇率中推断出来，这种套算出来的汇率称为理论交叉汇率。在现实世界中，很少会出现根据交易商对美元汇率报价计算出的理论交叉汇率不同于交易商报出的实际交叉汇率的情况。如果差异大到足以与购买及出售货币的交易成本相比，就出现了无风险套利机会。

平稳（非平稳）时间序列
https://zhuanlan.zhihu.com/p/425684691

金融时间序列分析——对收益率序列平稳化处理
https://blog.csdn.net/m0_37876745/article/details/108994950

谈谈时间序列的平稳性
https://blog.csdn.net/TimeFuture/article/details/120690021

- 时间序列分析中的许多预测和分析方法，如 ARMA、Granger 因果检验等，都要求输入序列是平稳的。
- 大多数时间序列都是非平稳的，比如一些股票的收盘价数据就是非平稳的。
- 如果时间序列包含明显的趋势和季节性，会影响算法准确预测时间序列的能力。
- 一般可以通过差分、取对数等方法转化成平稳时间序列。
    - 一步的差分其实就是今天的价格和昨天的价格相减再除以昨天的价格：`df['Close'] - df['Close'].shift(1)`
    - 对原始数据取对数然后再差分：`np.log(df['Close']) - np.log(df['Close'].shift(1)`
- 对转换后的数据集运行 Augmented Dicker-Fuller 测试，以确保平稳性




安装 ta-lib

    sudo apt install build-essential wget -y
    wget https://artiya4u.keybase.pub/TA-lib/ta-lib-0.4.0-src.tar.gz
    tar -xvf ta-lib-0.4.0-src.tar.gz
    cd ta-lib/
    ./configure --prefix=/usr
    make
    sudo make install

    pip install TA-Lib


backtrader绘图运行出matplotlib错的原因
https://www.jianshu.com/p/2dc8a671ab7a

backtrader与matplot 3.3不兼容，要降级到3.2，运行如下命令可降级：

    pip uninstall matplotlib
    pip install matplotlib==3.2.2

    pip uninstall pyfolio
    pip install git+https://github.com/quantopian/pyfolio

Pyfolio一行代码实现专业量化回测图表
https://zhuanlan.zhihu.com/p/376954470

pyfolio 是全球最大量化网站Quantopian开发的量化“三剑客”之一，另外两个分别是alphalens（用于多因子分析）和zipline（类似backtrader的回测框架）。pyfolio非常适合用于金融投资组合性能和风险分析，包括与Zipline和alphalens结合，输出专业的量化指标和图表分析结果。

[Python量化策略风险指标](https://mp.weixin.qq.com/s?__biz=MzUyMDk1MDY2MQ==&mid=2247483991&idx=1&sn=7e2a54011706fd88ff7cef2007f840d8&chksm=f9e3c4bdce944daba8cdd20fa7ca26704381779159f2aa25e66a2d1f527590e29c906df9a697&scene=21#wechat_redirect)

不显示 warnings
import warnings
warnings.filterwarnings('ignore')


PEG指标
https://baike.baidu.com/item/PEG%E6%8C%87%E6%A0%87/10904043

- 背景：
    - 投资者普遍习惯于使用市盈率来评估股票的价值，但是，当遇到一些极端情况时，市盈率的可操作性就有局限，比如市场上有许多远高于股市平均市盈率水平，甚至高达上百倍市盈率的股票，此时就无法用市盈率来评估这类股票的价值。
    - 但如果将市盈率和公司业绩成长性相对比，那些超高市盈率的股票看上去就有合理性了，投资者就不会觉得风险太大了，这就是PEG估值法。
- 定义：
    - PEG 指标(市盈率相对盈利增长比率)是用公司的市盈率除以公司的盈利增长速度。
    - 所谓 PEG，是用公司的市盈率（PE）除以公司未来 3 或 5 年的（每股收益复合增长率*100）。
    - 它由股票的未来市盈率除以每股盈余(EPS)的未来增长率预估值得出。
    - 它是在 PE 估值的基础上发展起来的，它弥补了 PE 对企业动态成长性估计的不足。
    - PE 仅仅反映了某股票当前价值，PEG 则把股票当前的价值和该股未来的成长联系了起来 。
- 特点
    - 通常成长型股票的 PEG 都会高于 1，甚至在 2 以上，投资者愿意给予其高估值，表明这家公司未来很有可能会保持业绩的快速增长，这样的股票就容易有超出想象的市盈率估值。
    - 通常价值型股票的 PEG 都会低于 1，以反映低业绩增长的预期。当 PEG 小于 1 时，要么是市场低估了这只股票的价值，要么是市场认为其业绩成长性可能比预期的要差。
- 使用
    - 粗略而言，PEG 值越低，股价遭低估的可能性越大。
    - 选股的时候选那些市盈率较低，同时它们的增长速度又是比较高的公司，这些公司有一个典型特点就是 PEG 会非常低。 
    - PEG 始终是主导股票运行的重要因素，所以寻找并持有低 PEG 的优质股票是获利的重要手段。
    - 当然，也不能够机械的单以 PEG 论估值，还必须结合国际市场、宏观经济、国家的产业政策、行业景气、资本市场阶段热点、股市的不同区域、上市公司盈利增长的持续性以及上市公司的其他内部情况等等多种因素来综合评价。
- 缺点
    - 须注意的是，PEG值的分子与分母均涉及对未来盈利增长的预测，出错的可能较大。
    - 计算 PEG 值所需的预估值，一般取市场平均预估(consensus estimates)，即追踪公司业绩的机构收集多位分析师的预测所得到的预估平均值或中值。

详解PE与PEG估值法
https://zhuanlan.zhihu.com/p/353770859



如何评价纳西姆·塔勒布的《反脆弱》？该书都有哪些优劣之处？
https://www.zhihu.com/question/24684650/answer/1174590096

本书的核心观点是：事物的发展从来都是非线性发展，一切事物都会从波动中获得收益或遭受损失，反脆弱就是能在波动性和不确定性中带来收益。

最好应对风险的方法是“以毒攻毒”，设计一个“反脆弱结构”。这里就是反脆弱概念，让自己经常暴露在风险中，提高自己生活的“波动性”，利用“波动性”平衡风险，并伺机利用风险获利。

通过非线性理论让我们知道，机遇某种程度比能力更重要，不能指望人生是线性发展，也并非“一分耕耘一分收获”，能力提高就能升职加薪。现实中，确定性事件和不确定性事件至少同样多。为了实现收入指数性增长而非线性增长，必须寻找新的增长点。

https://baijiahao.baidu.com/s?id=1732327796243580868&wfr=spider&for=pc

- 书中提出的应对不确定性的策略是杠铃策略——极端保守+极端投机的策略。其核心思想是为了避开中间地带，首要的是降低不利因素，而不是增加有利因素。
- 对于脆弱的系统而言，其他任何“增加效率、增加成功”的行为在“实现生存”这一需求面前都是不重要的。因此极端保守的策略显得如此重要。
- 同时，为了获得收益，又需要搭配极端投机策略。在投资中就体现为“现金+投机资产”或股票投资中的“高确定性标的+高投机性标的”的组合。
- 总结一下，反脆弱的杠铃策略在投资中的实践就是：先活下来，不要亏钱，再寻求收益。
- 脆弱的系统往往在大多数时候给予人们较好的体验，但在不确定性来临时不堪一击，其核心问题是不确定性来临时无法生存。

https://baijiahao.baidu.com/s?id=1698275248230462135&wfr=spider&for=pc

- 脆弱的事物依赖稳定环境，比如一个没有任何保护的股票多头策略，一旦市场大幅下跌将很可能会损失惨重。
- 强韧的事物不太依赖环境，环境怎么变它都不太会变。但是强韧不等于反脆弱，因为它无法从不确定性中获益。
- 反脆弱不是坚强，而是越挫越勇。外界环境越波动、随机、混乱越不会受伤，反而利用波动环境茁壮成长。就像人类的免疫系统，受到的冲击越多越坚强。
- 90%的现金和10%的期权就是一个比较典型的杠铃策略。一侧是极端的风险厌恶，一侧是极端的风险偏好，不走中间道路。当然，风险端的投资也要判断尽量有很高胜算才能参与，不能把期权当成赌大小的骰子。

钱：7步创造终身收入 笔记
https://book.douban.com/review/10111467/

重新认识风险
- 传统观点是收益和风险成长比，其实未然。
- 投资大师寻找风险小收益大的投资机会。
- 高风险并不一定都带来高收益，高收益也不一定都要高风险。
- 结构化票据、市场联动大额存单、固定指数年金等都是低风险高收益的投资对象。
- 投资还有运气成分，完全相同的策略，如果开始的年份不同，可能后面结果完全不同。

量化理财目标: 量化实现目标所需的财富水平，设定个人的理财目标：

- 财务安全：解决住房、水电、吃饭、交通、保险等问题
- 财务活力：财务安全 + 着装、娱乐、美食等额外需求
- 财务独立：现有生活水平
- 财务自由：相对有品质的生活
- 财务绝对自由：非常有品质的生活

采取行动
- 开源
    - 通过提升技能，增加收入。
    - 通过创业创新，增加收入。
- 节流
    - 改变生活方式以减少开支。
    - 压缩不必要的，或者低效的开支。
    - 提前偿还部分房贷本金，从而减少利息支出。
    - 为了压缩开支，减少税赋，搬家也是值得的。
- 储蓄
    - 建立储蓄账户、养老账户。
    - 拿出收入的固定比例，自动存入账户，建立「财务自由投资基金」。

达利欧组合

1. 达利欧在哈里·马科维茨（现代投资组合理论之父）的基础上创立了全天候投资策略。
2. 达利欧总结出 4 种不同的经济环境（经济季节），匹配四种不同的投资组合。
3. 达利欧全天候投资策略拥有高收益、高安全、低波动的特点。
4. 简化版的达利欧组合包括：
    - 长期国债：40%
    - 股票：30%
    - 中期国债：15%
    - 黄金：7.5%
    - 大宗商品：7.5%



1. 净利润: 净利润是一个企业经营的最终成果，净利润多，企业的经营效果好。
    - 第 1 步：计算销售净额，也就是营业收入，是指销售总额减销货退回与折让，以及销售税金后的余额；
    - 第 2 步：计算销售毛利，即销售净额减销售成本后的余额；
    - 第 3 步：计算销售利润，即销售毛利减销售费用、管理费用、财务费用等期间费用后的余额；
    - 第 4 步：计算营业利润，即销售利润加上其他业务利润后的余额；
    - 第 5 步：计算利润总额，即营业利润加营业外收支后的余额；
    - 第 6 步：计算所得税后的净利润，即利润总额减应计所得税(支出)后的余额。
2. 归母净利润：归属于母公司所有者的净利润才是投资人真正要关心的数字，它是由净利润扣除掉 “少数股东损益”得到。
    - 假设：甲上市公司旗下只有一家子公司 A，并且持其 70% 的股份。
    - 如果 2017 年，A 公司的净利润是 1 亿，且甲和 A 之间没有任何关联关系。
    - 上市公司在制定合并利润表时，在净利润科目中，增加不是 7000万 而是 1 亿。
    - 但真正属于上市公司股东，也就是所有股民的净利润要把另外 3000 万扣除掉。
    - 持有 A 公司 30% 股份的那些股东就被称之为少数股东，而这个 3000 万就叫作“少数股东权益”。
3. 扣非归母净利润：“归母净利润” 减去“非经常性损益”，即扣掉公司正常经营损益之外的一次性或者偶发性损失
    - 处置长期股权投资、固定资产、在建工程、无形资产、其他长期资产产生的损益；
    - 越权审批或无正式批准文件的税收返还、减免；
    - 各种形式的政府补贴；
    - 因不可抗力因素，如遭受自然灾害而计提的各项资产减值准备； 

--------------------------------------------------------
链接：https://wenku.baidu.com/view/02399cd5cbd376eeaeaad1f34693daef5ef71365.html

利润概念：
- 毛利润 = 主营业务净收入-主营业务支出-主营业务税金及附加
- 利润总额 = 主营业务净收入-主营业务支出-主营业务税金及附加+其他业务利润-营业费用-管理费用-财务费用+投资收益+营业外收入-营业务支出
- 净利润 = 利润总额-所得税
- 息税前利润 = 利润总额+利息支出
- 税前利润 = 利润总额
- 税后利润 = 净利润
- 归母净利润 = 净利润 - 少数股东损益(母公司未持有子公司股权部分的收益)
- 扣非归母净利润 = 归母净利润 - 非经常性损益(公司正常经营损益之外的一次性或者偶发性损失)

息税前利润通俗地说就是不扣除利息也不扣除所得税的利润, 顾名思义,是指不支付利息和所得税之前的利润.

毛利率高：说明行业好，业务模式好，竞争不激烈，有钱赚。
毛利率低：说明是夕阳行业，没钱赚，或者竞争太大，打价格战。
净利率高：说明管理水平高，成本和费用控制的好。
净利率低：说明运营效率低，管理水平差，公司不行。
俩都高：说明行业好，公司牛。
-------
这样理解的对不？

12种底部形态特征
https://www.zhihu.com/question/280125504/answer/2228221734

钱：7步创造终身收入
https://book.douban.com/subject/27667390/

7步创造终身收入：
1. 多存钱 （花小钱，存大钱）
2. 少上当（只投正路，不被骗钱）
3. 做规划（这辈子目标要赚到多少钱，需要多久，算下来年化收益目标是多少）
4. 做资产配置（三个水桶：一 安全安心水桶 只买固定收益，本金安全 二 风险成长水桶 做股票投资房地产投资 三 梦想水桶 追逐梦想）
5. 稳收入（强烈推荐保险年金）
6. 学大师（巴菲特达利欧邓普顿等）
7. 大财富（前面6步都只是小财富，人最大的财富就是健康，活的更爽和更久最重要，最带来幸福感的不是得到，而是付出和给予。不是物质而是激情，不是过去而是未来。

分享下《钱》的完整笔记
https://book.douban.com/review/10111467/

---


## mysql

部署MySQL延迟从库的几个好处
https://blog.51cto.com/imysql/3170546
https://dev.mysql.com/doc/refman/8.0/en/replication-delayed.html

MySQL延迟从库的好处主要有几点：
- 误删除时，能更快恢复数据。 有时候手抖了，把线上数据给误删除了，或者误删除库、表、其他对象，或不加WHERE条件的更新、删除，都可以让延迟从库在误操作前的时间点停下，然后进行恢复。
- 把延迟从库作为专用的备份节点。虽然有一定的延迟，但并不影响利用该节点作为备份角色，也不影响生产节点数据库库。
- 还可以把延迟从库当做一些问题、案例研究的对象。个别时候，可能有些binlog event在普通从库上会有问题（例如早期版本中无主键会导致从库更新非常慢的经典问题），这时就有时间在延迟从库上慢慢琢磨研究了。

---

## php

How do I create a copy of an object in PHP?
https://stackoverflow.com/questions/185934/how-do-i-create-a-copy-of-an-object-in-php

$objectB = clone $objectA;

---

## linux

rc.local

    printf '%s\n' '[Install]' 'WantedBy=multi-user.target' 'Alias=rc-local.service' | sudo tee -a /usr/lib/systemd/system/rc-local.service

    echo "
    [Install]
    WantedBy=multi-user.target
    Alias=rc-local.service
    " >> /usr/lib/systemd/system/rc-local.service

    tail /usr/lib/systemd/system/rc-local.service
    echo '#!/bin/bash' > /etc/rc.local
    chmod +x /etc/rc.local
    systemctl enable rc-local
    systemctl start rc-local
    systemctl status rc-local

iptables

    iptables -A INPUT  -i eth0 -p tcp -s 140.143.1.1--dport 8080 -m state --state NEW,ESTABLISHED -j ACCEPT
    iptables -A INPUT -p tcp --dport 8080 -j DROP
    iptables -L -n
    iptables-save >/etc/iptables-script
    cat /etc/iptables-script
    iptables-restore </etc/iptables-script
    echo '/sbin/iptables-restore </etc/iptables-script' >>/etc/rc.local

linux命令：iptables、modprobe装载模块、网络防火墙服务
https://blog.51cto.com/woyaoxuelinux/1906316

- iptables 的前身叫ipfirewall （内核1.x时代）,这是一个作者从freeBSD上移植过来的，能够工作在内核当中的，对数据包进行检测的一款简易访问控制工具。但是ipfirewall工作功能极其有限(它需要将所有的规则都放进内核当中，这样规则才能够运行起来，而放进内核，这个做法一般是极其困难的)。
- 当内核发展到2.x系列的时候，软件更名为 ipchains，它可以定义多条规则，将他们串起来，共同发挥作用，
- 而现在，它叫做iptables，可以将规则组成一个列表，实现绝对详细的访问控制功能。
- 他们都是工作在用户空间中，定义规则的工具，本身并不算是防火墙。
- 而放入内核的地方必须要是特定的位置，必须是 tcp/ip 的协议栈经过的地方，叫做 netfilter.(网络过滤器)

---

## postgree

PostgreSQL 生成随机数字、字符串、日期、验证码以及 UUID
https://blog.csdn.net/horses/article/details/109215148

生成 0 到 1 之间的随机数

    SELECT random();

任意两个数字之间的随机数

    low + RANDOM() * (high - low)

---

## elasticsearch

Elasticsearch性能调优之磁盘读写性能优化
https://blog.csdn.net/lm324114/article/details/105029393/

- 禁用不需要的功能
    - 聚合：doc values
    - 搜索：倒排索引，index
    - 评分：norms
    - 近似匹配：index_options（freqs）
- 不要用默认的动态 string 类型映射
    - 默认的动态 string 类型映射会将 string 类型的 field 同时映射为 text 类型以及 keyword 类型，这会浪费磁盘空间，因为我们不一定两种都需要。
- 禁止_all field: 
    - _all field会将document中所有field的值都合并在一起进行索引，很耗费空空间，如果不需要一次性对所有的field都进行搜索，那么最好禁用_all field。
- 使用 best_compression
    - _source field 和其他 field 都很耗费磁盘空间，最好是对其使用 best_compression 进行压缩。 
- 用最小的最合适的数字类型
    - es 支持 4 种数字类型，byte，short，integer，long。如果最小的类型就合适，那么就用最小的类型。


如果我们有一个叫做 foo 的数字类型 field，我们要对这个字段运行 histograms aggr 聚合操作，但是可能我们并不需要对这个字段进行搜索，那么就可以禁止为这个字段生成倒排索引，只需要 doc value 正排索引即可。

    "foo": {
        "type": "integer",
        "index": false
    }

text 类型的 field 会存储 norm 值，用来计算 doc 的相关度分数，如果我们需要对一个 text field 进行搜索，但是不关心这个 field的分数，那么可以禁用 norm 值。

    "foo": {
        "type": "text",
        "norms": false
    }

text field 还会存储出现频率以及位置，出现频率也是用来计算相关度分数的，位置是用来进行 phrase query 这种近似匹配操作的，如果我们不需要执行 phrase query 近似匹配，那么可以禁用位置这个属性：

    "foo": {
        "type": "text",
        "index_options": "freqs"
    }

如果我们不关心相关度频分，我们可以配置 es 仅仅为每个 term 索引对应的 document，我们可以对这个 field 进行搜索，但是 phrase query 这种近似匹配会报错，而且相关度评分会不准确。

    "foo": {
        "type": "text",
        "norms": false,
        "index_options": "freqs"
    }

